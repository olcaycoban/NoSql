{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('pyspark-by-examples').getOrCreate()\n",
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\", 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.csv(\"C:\\Interpreter\\mockd.csv\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\").load(\"C:\\Interpreter\\mockd.csv\")\n",
    "#       or\n",
    "#df = spark.read.format(\"org.apache.spark.sql.csv\").load(\"/tmp/resources/zipcodes.csv\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.read.option(\"header\",True) \\\n",
    "     .csv(\"C:\\Interpreter\\mockd.csv\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "df=spark.read.csv(['C:\\\\Interpreter\\\\data3.csv','C:\\\\Interpreter\\\\data.csv',], header=True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+---------+------+----------+------------+\n",
      "|         _c0|    _c1|      _c2|   _c3|       _c4|         _c5|\n",
      "+------------+-------+---------+------+----------+------------+\n",
      "|subcriber_sk|   name|  surname|fatura|fatura_gun|kampanya_tip|\n",
      "|           2| Anders|  Reinger|    35|16.11.2020|         Mrs|\n",
      "|        2987|  Barry|   Falcus|    60|15.01.2020|          Ms|\n",
      "|        8807|  Dolli|   Willas|    98|03.09.2020|   Honorable|\n",
      "|          00| Verina|   Tysall|    63|25.09.2020|          Mr|\n",
      "|          68|  Frank|   Bushby|    38|13.01.2020|          Dr|\n",
      "|         438|Ermanno|Philipeau|    36|10.03.2020|         Rev|\n",
      "|       74314|Janella|   Lebbon|    42|30.12.2019|         Rev|\n",
      "|         941|Stormie|Roelofsen|    61|15.06.2020|         Mrs|\n",
      "|        8022| Melvin|   Hawson|    48|20.04.2020|          Ms|\n",
      "+------------+-------+---------+------+----------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = spark.read.options(delimiter=',') \\\n",
    "  .csv(\"C:\\Interpreter\\mockd.csv\")\n",
    "df3.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      "\n",
      "+------------+----------+---------+------+----------+------------+\n",
      "|         _c0|       _c1|      _c2|   _c3|       _c4|         _c5|\n",
      "+------------+----------+---------+------+----------+------------+\n",
      "|subcriber_sk|      name|  surname|fatura|fatura_gun|kampanya_tip|\n",
      "|           2|    Anders|  Reinger|    35|16.11.2020|         Mrs|\n",
      "|        2987|     Barry|   Falcus|    60|15.01.2020|          Ms|\n",
      "|        8807|     Dolli|   Willas|    98|03.09.2020|   Honorable|\n",
      "|          00|    Verina|   Tysall|    63|25.09.2020|          Mr|\n",
      "|          68|     Frank|   Bushby|    38|13.01.2020|          Dr|\n",
      "|         438|   Ermanno|Philipeau|    36|10.03.2020|         Rev|\n",
      "|       74314|   Janella|   Lebbon|    42|30.12.2019|         Rev|\n",
      "|         941|   Stormie|Roelofsen|    61|15.06.2020|         Mrs|\n",
      "|        8022|    Melvin|   Hawson|    48|20.04.2020|          Ms|\n",
      "|           0|     Morty| Andersen|    64|08.07.2020|          Dr|\n",
      "|         693|   Hermine|  Herrero|    44|12.05.2020|         Rev|\n",
      "|          87|     Cordy|  Rodgers|    26|15.11.2020|          Ms|\n",
      "|           5|     Winny| Bruneton|    79|08.01.2020|          Ms|\n",
      "|           2|     Dedie|    Riply|    82|11.06.2020|   Honorable|\n",
      "|         851|   Padgett|      Gee|    48|25.03.2020|          Dr|\n",
      "|           6|     Anica|  Krolman|    28|29.02.2020|          Ms|\n",
      "|         877|     Nicki|   Filkov|    46|18.02.2020|          Mr|\n",
      "|         259|Fredericka| Lutwyche|    40|26.06.2020|          Mr|\n",
      "|       08813|      Alma|   Possel|    47|15.09.2020|          Dr|\n",
      "+------------+----------+---------+------+----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4 = spark.read.options(inferSchema='True',delimiter=',') \\\n",
    "  .csv(\"C:\\Interpreter\\mockd.csv\")\n",
    "df4.printSchema()\n",
    "df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      "\n",
      "+---------+-------------+---------------------------------+------+-------------+\n",
      "|_c0      |_c1          |_c2                              |_c3   |_c4          |\n",
      "+---------+-------------+---------------------------------+------+-------------+\n",
      "|Banky    |Russon       |brusson0@nih.gov                 |Male  |Indonesia    |\n",
      "|Gelya    |Bee          |gbee1@addtoany.com               |Female|Malta        |\n",
      "|Magdalene|Loseby       |mloseby2@chronoengine.com        |Female|Turkmenistan |\n",
      "|Waylon   |Tugman       |wtugman3@mayoclinic.com          |Male  |Philippines  |\n",
      "|Rice     |Rustadge     |rrustadge4@hexun.com             |Male  |Thailand     |\n",
      "|Erin     |Buckenhill   |ebuckenhill5@google.de           |Male  |Greece       |\n",
      "|Joanie   |Broadhurst   |jbroadhurst6@sohu.com            |Female|Panama       |\n",
      "|Tomaso   |Bartlomieczak|tbartlomieczak7@sciencedirect.com|Male  |Greece       |\n",
      "|Josias   |Gommes       |jgommes8@ask.com                 |Male  |Mexico       |\n",
      "|Andie    |Alldre       |aalldre9@kickstarter.com         |Female|Lithuania    |\n",
      "|Shanon   |Castrillo    |scastrilloa@bluehost.com         |Female|China        |\n",
      "|Bird     |Veare        |bveareb@arizona.edu              |Female|New Zealand  |\n",
      "|Tova     |Braley       |tbraleyc@nydailynews.com         |Female|China        |\n",
      "|Lynn     |Croll        |lcrolld@canalblog.com            |Female|Tunisia      |\n",
      "|Kristin  |Hubberstey   |khubbersteye@sogou.com           |Female|Somalia      |\n",
      "|Gabi     |Jakubowski   |gjakubowskif@cdc.gov             |Male  |Finland      |\n",
      "|Karna    |Bowbrick     |kbowbrickg@wikimedia.org         |Female|Thailand     |\n",
      "|Elane    |McIver       |emciverh@google.com.au           |Female|Poland       |\n",
      "|Raynard  |Boards       |rboardsi@sogou.com               |Male  |United States|\n",
      "|Eleanore |Trevor       |etrevorj@slashdot.org            |Female|Sweden       |\n",
      "+---------+-------------+---------------------------------+------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4 = spark.read.option(\"inferSchema\",True) \\\n",
    "                .option(\"delimiter\",\",\") \\\n",
    "  .csv(\"C:\\Interpreter\\data.csv\")\n",
    "df4.printSchema()\n",
    "df4.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-------------------------+------+------------+\n",
      "|Banky    |Russon    |brusson0@nih.gov         |Male  |Indonesia   |\n",
      "+---------+----------+-------------------------+------+------------+\n",
      "|Gelya    |Bee       |gbee1@addtoany.com       |Female|Malta       |\n",
      "|Magdalene|Loseby    |mloseby2@chronoengine.com|Female|Turkmenistan|\n",
      "|Waylon   |Tugman    |wtugman3@mayoclinic.com  |Male  |Philippines |\n",
      "|Rice     |Rustadge  |rrustadge4@hexun.com     |Male  |Thailand    |\n",
      "|Erin     |Buckenhill|ebuckenhill5@google.de   |Male  |Greece      |\n",
      "+---------+----------+-------------------------+------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5 = spark.read.options(header='True', inferSchema='True', delimiter=',') \\\n",
    "  .csv(\"C:\\Interpreter\\data.csv\")\n",
    "df5.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+---------+------+----------+------------+\n",
      "|subcriber_sk|   name|  surname|fatura|fatura_gun|kampanya_tip|\n",
      "+------------+-------+---------+------+----------+------------+\n",
      "|           2| Anders|  Reinger|    35|16.11.2020|         Mrs|\n",
      "|        2987|  Barry|   Falcus|    60|15.01.2020|          Ms|\n",
      "|        8807|  Dolli|   Willas|    98|03.09.2020|   Honorable|\n",
      "|          00| Verina|   Tysall|    63|25.09.2020|          Mr|\n",
      "|          68|  Frank|   Bushby|    38|13.01.2020|          Dr|\n",
      "|         438|Ermanno|Philipeau|    36|10.03.2020|         Rev|\n",
      "|       74314|Janella|   Lebbon|    42|30.12.2019|         Rev|\n",
      "|         941|Stormie|Roelofsen|    61|15.06.2020|         Mrs|\n",
      "|        8022| Melvin|   Hawson|    48|20.04.2020|          Ms|\n",
      "|           0|  Morty| Andersen|    64|08.07.2020|          Dr|\n",
      "+------------+-------+---------+------+----------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.read.options(header='True').csv(\"C:\\Interpreter\\mockd.csv\")\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType,IntegerType,StringType,DoubleType,BooleanType\n",
    "schema = StructType() \\\n",
    "      .add(\"RecordNumber\",IntegerType(),True) \\\n",
    "      .add(\"Zipcode\",IntegerType(),True) \\\n",
    "      .add(\"ZipCodeType\",StringType(),True) \\\n",
    "      .add(\"City\",StringType(),True) \\\n",
    "      .add(\"State\",StringType(),True) \\\n",
    "      .add(\"LocationType\",StringType(),True) \\\n",
    "      .add(\"Lat\",DoubleType(),True) \\\n",
    "      .add(\"Long\",DoubleType(),True) \\\n",
    "      .add(\"Xaxis\",IntegerType(),True) \\\n",
    "      .add(\"Yaxis\",DoubleType(),True) \\\n",
    "      .add(\"Zaxis\",DoubleType(),True) \\\n",
    "      .add(\"WorldRegion\",StringType(),True) \\\n",
    "      .add(\"Country\",StringType(),True) \\\n",
    "      .add(\"LocationText\",StringType(),True) \\\n",
    "      .add(\"Location\",StringType(),True) \\\n",
    "      .add(\"Decommisioned\",BooleanType(),True) \\\n",
    "      .add(\"TaxReturnsFiled\",StringType(),True) \\\n",
    "      .add(\"EstimatedPopulation\",IntegerType(),True) \\\n",
    "      .add(\"TotalWages\",IntegerType(),True) \\\n",
    "      .add(\"Notes\",StringType(),True)\n",
    "      \n",
    "df_with_schema = spark.read.format(\"csv\") \\\n",
    "      .option(\"header\", True) \\\n",
    "      .schema(schema) \\\n",
    "      .load(\"c:\\Interpreter\\data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- RecordNumber: integer (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- ZipCodeType: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- LocationType: string (nullable = true)\n",
      " |-- Lat: double (nullable = true)\n",
      " |-- Long: double (nullable = true)\n",
      " |-- Xaxis: integer (nullable = true)\n",
      " |-- Yaxis: double (nullable = true)\n",
      " |-- Zaxis: double (nullable = true)\n",
      " |-- WorldRegion: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- LocationText: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Decommisioned: boolean (nullable = true)\n",
      " |-- TaxReturnsFiled: string (nullable = true)\n",
      " |-- EstimatedPopulation: integer (nullable = true)\n",
      " |-- TotalWages: integer (nullable = true)\n",
      " |-- Notes: string (nullable = true)\n",
      "\n",
      "+------------+-------+--------------------+------+------------+------------+----+----+-----+-----+-----+-----------+-------+------------+--------+-------------+---------------+-------------------+----------+-----+\n",
      "|RecordNumber|Zipcode|         ZipCodeType|  City|       State|LocationType| Lat|Long|Xaxis|Yaxis|Zaxis|WorldRegion|Country|LocationText|Location|Decommisioned|TaxReturnsFiled|EstimatedPopulation|TotalWages|Notes|\n",
      "+------------+-------+--------------------+------+------------+------------+----+----+-----+-----+-----+-----------+-------+------------+--------+-------------+---------------+-------------------+----------+-----+\n",
      "|        null|   null|  gbee1@addtoany.com|Female|       Malta|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n",
      "|        null|   null|mloseby2@chronoen...|Female|Turkmenistan|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n",
      "|        null|   null|wtugman3@mayoclin...|  Male| Philippines|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n",
      "|        null|   null|rrustadge4@hexun.com|  Male|    Thailand|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n",
      "|        null|   null|ebuckenhill5@goog...|  Male|      Greece|        null|null|null| null| null| null|       null|   null|        null|    null|         null|           null|               null|      null| null|\n",
      "+------------+-------+--------------------+------+------------+------------+----+----+-----+-----+-----+-----------+-------+------------+--------+-------------+---------------+-------------------+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_schema.printSchema()\n",
    "df_with_schema.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATAFRAME TO CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pandasDF = df.toPandas()\n",
    "print(pandasDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandasDF.to_csv(\"olcay.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
